{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "In this notebook, we will walk through one main neural nets example. And that is, classifying the infamous MNIST dataset. **If you have no experience with neural nets prior to this notebook, I recommend doing a quick search for an \"intro to neural nets\"**, there are multiple tutorials/blog posts out there and you can choose the one that works for you.\n",
    "\n",
    "Here, we will use the `Flux` package, but if you want to look at other packages I encourage you to look at `Knet.jl` and `TensorFlow.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST\n",
    "using Flux: onehotbatch, argmax, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "using Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAESmlDQ1BrQ0dDb2xvclNwYWNlR2VuZXJpY0dyYXkAADiNjVVbaBxVGP535+wGJA4+aBtaaAcvbSlpmESricXa7Wa7SRM362ZTmyrKZHY2O93ZmXFmdpuEPpWCb1oQpK+C+hgLIlgv2LzYl4rFkko1DwoRWowgKH1S8DtnJpvZDV5mOOd857+d//wXDlHPH5rrWkmFqGEHXr6UmT09e0bpuUlJkqmX8Gm672aKxUmObcc2aNt3/zYl+HrrELe1nf+vX6pi+DrWaxhOxdcbRAmVKF3VXS8g6rkM+vC5wOX4JvDD9XIpC7wOLEe6/Hskb9iGZ+pK3tMWlaLnVE0r7ut/8f/X17Cam+ftxej169MTWA/C54uGPTMNfAB4WddyHPcD326ZpwohTibd4HgplE8ONOszmYh+uuqdmInoF2vNMY4HgJeXauWXgB8CXrPnClOR/EbdmeB2+oikPt3PngF+HFitGeM8Twpw2XNKUxE9qBijOeBngS+bwXg5tC9967emcyFmtFTLFsKz2MBZ7WQReAfwUcPKl0I7rOwGRW5zGHjBtgqToc/siuHnoruz74NaeSyUTyUDr8x1HwXeVzVPjIf+p8Zq3lgp9CcVuJaoraeBl71mid99H/C65uXyoc30AxVtlMf5KeAhOpXQyCCH5jDrZNNfuK9PJrUEcskDr4q9RXlI2Bgedjp4eSCNFoGKMSkDOy4T7hSqYKfQvNDyBeJW7kZWsnvepyaoNdoAtQb0Av0oKAv0EzWwZkFtgjffZTeL1aYleKBEnt2LbDpsJ1PZkxhH2CR7jg2zEVLY8+wYO8pGQR1hR2Lex33n3t1rW3od58Z9X4FEAB0LntnQ8UWkluhP8OtCMhatS7uaB1z3nTcveK+Z+jdv/dYRPR/yod2fYdER9Jju9fOf98Xju8o+eeVW7/XzNBXPkshbpTtLqfXU3dQq5juptbiN1A+pNfx3tt2X+7OZlc3cZsCzBK2BYQqO37bWBA4wV4XOoQ6Lcey07c9jONtOcf4xJhxropZiN6val3a57qsf8GgabxTuF+hCv3pF3VDfU79Tf1VX1XeBfpHelj6WvpCuSp9KN0iRrkkr0pfSV9KH0mfYfQTqinS1q5LmO6unXbN6VGGcG4h8Z2JR4dTN+50Fb8tTQ8Sh84TO6m+fJR+Xd8uPyaPyXvkJeVI+KB+Wj8k75SGMQXlM3g/O7naUrCgDZlfHmTQrYhXmyRbdpIHfwKzF/AplYzFPPIg4m11dvtn9pujGsDod7DWaATLpnND1RX5s0f3d2kvidCfxMo8g28MG2XjUgxl2GF040dGPw7xL07n0aDpDSvpgeiQ9mD7J8VbtpveDO4I5F/PeaEd2q4fmRJ3WRYxaQsLHTIGxEPBHJuu4i545XwuUIVV9RsngeTWUcVsf6Fc0y1IEy1c8wze8llEZIP52h8/T7y+KNzmx44be9FrRm5VIfE30N7ePkzQTJdzgAAAAOGVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAACoAIABAAAAAEAAABwoAMABAAAAAEAAABwAAAAAP1Kc4sAAAHUSURBVGgF7ZnPKwVRFMcfWUqRpZQNKYpSYqNYUNZWNm+pbFj5F+wsKGVlbUsW8i9I2VhISpQsJBYs/PqcujVZvJl77+SU0zn17d7XnfdO3+/n3Zk38xoNL0/AE/AEPAFPwBPwBP5/Am11LSzxAQdoBe2hb1RW7WWLf7Fmv2FthmfkPhayH2C8reBgP1J3WPEVSF+2H2lHeijFO0aY9oWXb4yfxVLLmf1I1R3WYrgMqd5Aa43xviW5YkHdof2GtRj2BDSvjA8FptKZ/UjVHWYz7ITUZKB1zHhUSq5YVHdov2E2wymwjAY0sXtQDrcfqbrDLIZdsBgO/J4Yt8M8ZlB3aL9hFsNxYK0j4beLblBs2Y9U3WHWPf4JwOaQMJxGVyi21B3ab5i8D7uBdYmE4Qf6QillP1J1h8kMJwC2iB7RDrpGKaXu0H7DJIZyP7iJ5LnoIdpHqWU/UnWH0QzlHLqK5Pn2KdpAMc9lOOxXqTu03zD6N808JLaQsJxFck3MKfuRqjuM3odNgA2hO/SOckvdof2GUQwXADaILtAMekG5ZT9SdYeV59J+YMn93zMSlueoTqk7tN+wch9KBHKQ/LdUl5+wtx+pukOJ1csT8AQ8AU+gXgI/C5EsSGIuCyUAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = MNIST.images()\n",
    "colorview(Gray, imgs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Gray{Normed{UInt8,8}},2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(imgs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will transofrm the gray scale values to Float32 types. Here, using Float32 will speedup the neural network substantially withough compromising the quality of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000-element Array{Array{Float32,2},1}:\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " ⋮\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myFloat32(X) = Float32.(X)\n",
    "fpt_imgs = myFloat32.(imgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float32,2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(fpt_imgs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a few helpful functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize(x) = x[:]\n",
    "vectorized_imgs = vectorize.(fpt_imgs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Array{Float32,1},1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(vectorized_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again make use of `...` as the splat operator to concatenate all images into one matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = hcat(vectorized_imgs...)\n",
    "size(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, every column in `X` is an image of a number. We have `60,000` images. When reshaped into a 28-by-28 matrix, and displayed as an image, can be seen as a handwritten number. Here is an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×28 reinterpret(Gray{Float32}, ::Array{Float32,2}):\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱  \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onefigure = X[:,3]\n",
    "t1 = reshape(onefigure,28,28)\n",
    "colorview(Gray,t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will obtain the labels. These are the true labels for the `60,000` images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = MNIST.labels()\n",
    "labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these labels, we will create a new output column for each image. These columns will be indicator vectors of where the correct label is.\n",
    "\n",
    "For example if the figure corresponding to column `X[:,i]` is a `3`, the `i'th` column in this new matrix `Y` is `[0 0 0 1 0 0 0 0 0 0]`. (It is the entry number 4 because entry 1 corresponds to the digit 0, so the counting starts from zero). The `onehotbatch` function allows us to create this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×60000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  1  0  0  1  0  1  0  0  0  0     0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  0  0  0  0  1  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  0  0  1  0  1     0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  1  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  1  0  …  0  0  0  0  0  1  0  0  0  1  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     1  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  1  0  0  0  0  0  1  0  0  0  1\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0     0  0  1  0  1  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = onehotbatch(labels, 0:9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will actually build our neural network. We will use two layers. The hidden layer will have 32 nodes, and the output layer will have 10 nodes. i.e. we will go from: `28*28 => 32 => 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 32, relu), Dense(32, 10), softmax)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does `m`, the neural network mean here? \n",
    "\n",
    "If you've worked with neural networks before you know that the solution is often not found by just one pass on the neural network. One pass happens, and a solution is generated at the output layer, then this solution is compared to the ground truth solution we already have (the columns from `Y`), and the network goes back and adjusts its weights and parameters and then try again. Here, since `m` is not \"trained\" yet, one pass of `m` on a figure generates the following (not-so-great) answer. We will see later how this changes after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.09733525\n",
       " 0.08215944\n",
       " 0.083417185\n",
       " 0.21038684\n",
       " 0.0866223\n",
       " 0.075022995\n",
       " 0.0848846\n",
       " 0.06997362\n",
       " 0.14776614\n",
       " 0.06243159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(onefigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run our neural network, we need a loss function and an accuracy function. The accuracy function is used to compare the output result from the output layer in the neural network to the groundtruth result. The loss function is used to evaluate the performance of the overall model after new weights have been recalculated at each pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = Flux.crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(argmax(m(x)) .== argmax(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will repeat our data so that we have more samples to pass to the neural network, which means there will be more chances for corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetx = repeated((X, Y), 200)\n",
    "C = collect(datasetx);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a function to display the loss at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#3 (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb = () -> @show(loss(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[0.0071736737 -0.03036321 … 0.032545816 -0.023747275; -0.028356241 -0.083176464 … 0.027189756 0.0400881; … ; 0.082404144 -0.05686704 … -0.08054515 0.039617267; -0.002954497 0.013985546 … 0.078786455 -0.02831656], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.08932363 0.094673775 … -0.17531838 0.13151759; 0.3476475 -0.3684938 … -0.30146545 -0.24876234; … ; -0.15957415 -0.2758126 … -0.0608175 -0.111767635; 0.12899315 -0.11270302 … -0.31407237 -0.08888577], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = Flux.params(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to train the model, we will use the `Flux.train!` function. Let's take a look at the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "train!(loss, params, data, opt; cb)\n",
       "\\end{verbatim}\n",
       "For each datapoint \\texttt{d} in \\texttt{data} compute the gradient of \\texttt{loss(d...)} through backpropagation and call the optimizer \\texttt{opt}.\n",
       "\n",
       "In case datapoints \\texttt{d} are of numeric array type, assume no splatting is needed and compute the gradient of \\texttt{loss(d)}.\n",
       "\n",
       "A callback is given with the keyword argument \\texttt{cb}. For example, this will print \"training\" every 10 seconds (using \\href{@ref}{\\texttt{Flux.throttle}}):\n",
       "\n",
       "train!(loss, params, data, opt,          cb = throttle(() -> println(\"training\"), 10))\n",
       "\n",
       "The callback can call \\href{@ref}{\\texttt{Flux.stop}} to interrupt the training loop.\n",
       "\n",
       "Multiple optimisers and callbacks can be passed to \\texttt{opt} and \\texttt{cb} as arrays.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "train!(loss, params, data, opt; cb)\n",
       "```\n",
       "\n",
       "For each datapoint `d` in `data` compute the gradient of `loss(d...)` through backpropagation and call the optimizer `opt`.\n",
       "\n",
       "In case datapoints `d` are of numeric array type, assume no splatting is needed and compute the gradient of `loss(d)`.\n",
       "\n",
       "A callback is given with the keyword argument `cb`. For example, this will print \"training\" every 10 seconds (using [`Flux.throttle`](@ref)):\n",
       "\n",
       "train!(loss, params, data, opt,          cb = throttle(() -> println(\"training\"), 10))\n",
       "\n",
       "The callback can call [`Flux.stop`](@ref) to interrupt the training loop.\n",
       "\n",
       "Multiple optimisers and callbacks can be passed to `opt` and `cb` as arrays.\n"
      ],
      "text/plain": [
       "\u001b[36m  train!(loss, params, data, opt; cb)\u001b[39m\n",
       "\n",
       "  For each datapoint \u001b[36md\u001b[39m in \u001b[36mdata\u001b[39m compute the gradient of \u001b[36mloss(d...)\u001b[39m through\n",
       "  backpropagation and call the optimizer \u001b[36mopt\u001b[39m.\n",
       "\n",
       "  In case datapoints \u001b[36md\u001b[39m are of numeric array type, assume no splatting is\n",
       "  needed and compute the gradient of \u001b[36mloss(d)\u001b[39m.\n",
       "\n",
       "  A callback is given with the keyword argument \u001b[36mcb\u001b[39m. For example, this will\n",
       "  print \"training\" every 10 seconds (using \u001b[36mFlux.throttle\u001b[39m):\n",
       "\n",
       "  train!(loss, params, data, opt, cb = throttle(() -> println(\"training\"),\n",
       "  10))\n",
       "\n",
       "  The callback can call \u001b[36mFlux.stop\u001b[39m to interrupt the training loop.\n",
       "\n",
       "  Multiple optimisers and callbacks can be passed to \u001b[36mopt\u001b[39m and \u001b[36mcb\u001b[39m as arrays."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Flux.train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 2.2564037f0\n",
      "loss(X, Y) = 0.9608722f0\n",
      "loss(X, Y) = 0.5360268f0\n",
      "loss(X, Y) = 0.4031882f0\n",
      "loss(X, Y) = 0.34638894f0\n",
      "loss(X, Y) = 0.31118682f0\n",
      "loss(X, Y) = 0.2873739f0\n"
     ]
    }
   ],
   "source": [
    "opt = ADAM()\n",
    "Flux.train!(loss, ps, datasetx, opt, cb = throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now get the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.00024723905\n",
       " 1.2693711f-7\n",
       " 4.158335f-5\n",
       " 0.0026686336\n",
       " 6.259864f-6\n",
       " 0.000100415775\n",
       " 2.6722677f-7\n",
       " 0.99650407\n",
       " 7.106942f-5\n",
       " 0.00036042536"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...);\n",
    "test_image = m(tX[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax(test_image) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×28 Array{Gray{Float32},2} with eltype Gray{Float32}:\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱  \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = reshape(tX[:,1],28,28)\n",
    "colorview(Gray, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the image we tried a few cells earlier and returned the \"not-so-great\" answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.998697\n",
       " 3.4294123f-10\n",
       " 8.7849956f-5\n",
       " 0.0001142274\n",
       " 2.1881644f-7\n",
       " 0.0008209261\n",
       " 2.9258348f-5\n",
       " 8.827988f-5\n",
       " 0.000115546325\n",
       " 4.6671623f-5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onefigure = X[:,2]\n",
    "m(onefigure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Flux.OneHotVector:\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally...\n",
    "After finishing this notebook, you should be able to:\n",
    "- [ ] prepare data to fit the format to create a neural network using Flux.jl\n",
    "- [ ] create a neural network with Flux.jl\n",
    "- [ ] creating an accuracy function and loss function to be passed to train the neural network\n",
    "- [ ] train the neural network\n",
    "- [ ] describe a few tips that can help make your nerual network faster or more accurate (such as using Float32 as opposed to Float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🥳 One cool finding\n",
    "\n",
    "We ran a trained a neural network on a dataset of of handwritten digits (called the MNIST dataset). At the end, we were able to pass this figure to the neural network and the return result was:\n",
    "\n",
    "<img src=\"data/1001.png\" width=\"40\">\n",
    "\n",
    "```\n",
    "10-element Array{Float32,1}:\n",
    " 0.00029263002\n",
    " 1.5993925f-5\n",
    " 0.0002862561\n",
    " 0.0035434738\n",
    " 1.388653f-5\n",
    " 2.4878627f-5\n",
    " 6.433018f-7\n",
    " 0.99414164 ### <= this is the highest number!\n",
    " 0.000118321994\n",
    " 0.0015623316\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
